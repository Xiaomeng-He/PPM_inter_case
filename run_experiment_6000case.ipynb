{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t8wv2HatJPTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b5a31f-d1aa-4df3-fd82-aed4c7fe2dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torchmetrics-1.5.1-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "oLyrwM4QJcZn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from preprocessing import sort_log, debiasing, create_time_features, mapping_case_id, add_soc_eoc\n",
        "from preprocessing import train_mapping_event_name, test_mapping_event_name, train_standardize, test_standardize\n",
        "from train_test_split import create_table_without_discard_case, get_train_test_split_point\n",
        "from create_prefix_suffix import create_log_prefix_tensor, create_trace_prefix_tensor, create_trace_suffix_tensor\n",
        "from create_model import Encoder, Decoder, Seq2Seq_one_input, Seq2Seq_cat, Seq2Seq_add, Seq2Seq_mul, normalized_DL_distance"
      ],
      "metadata": {
        "id": "cl15hufLvYcp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create training dataloader pipeline\n",
        "The steps in this section mirror the steps in the function *create_train_valid_dataloader* from *dataloader_pipeline*\n",
        "\n",
        "The steps are executed separately to allow for inspection of intermediate results."
      ],
      "metadata": {
        "id": "pFGhCeUYu8rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "csv_path = 'BPIC2017_6000cases.csv'\n",
        "end_date = '2017-01'\n",
        "max_duration = 47.81\n",
        "test_ratio = 0.3\n",
        "validation_ratio = 0.2\n",
        "log_prefix_length = 30\n",
        "trace_prefix_length = 15\n",
        "trace_suffix_length = 35\n",
        "num_act = 28 # number of activity labels in training set: 24"
      ],
      "metadata": {
        "id": "IfxhLnpzwXri"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_name = 'train'\n",
        "log_col_name = ['concept:name', 'log_ts_pre']\n",
        "trace_prefix_col_name = ['concept:name', 'trace_ts_start', 'trace_ts_pre']\n",
        "trace_suffix_col_name = ['concept:name', 'trace_ts_pre']\n",
        "categorical_features = ['concept:name']\n",
        "continuous_features = ['log_ts_pre', 'trace_ts_pre', 'trace_ts_start']\n",
        "case_id = 'case:concept:name'\n",
        "timestamp = 'time:timestamp'\n",
        "event_name = 'concept:name'\n",
        "event_idx = 'event_idx'"
      ],
      "metadata": {
        "id": "EVnLNA2gvB42"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Tranform csv to dataframe\n",
        "df = pd.read_csv(csv_path)\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "JFvvbYPHviJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee4d859f-b5bf-4e92-fbfa-cad62c285ebe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 230225 entries, 0 to 230224\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count   Dtype \n",
            "---  ------             --------------   ----- \n",
            " 0   Unnamed: 0         230225 non-null  int64 \n",
            " 1   case:concept:name  230225 non-null  object\n",
            " 2   time:timestamp     230225 non-null  object\n",
            " 3   concept:name       230225 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 7.0+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of cases:\", df[case_id].nunique())\n",
        "print(\"Number of activity labels:\", df[event_name].nunique())"
      ],
      "metadata": {
        "id": "NrzQQd8HvnmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "717f975c-8a6b-45f6-e292-c648241bac9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cases: 6000\n",
            "Number of activity labels: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Sort dataframe by timestamp\n",
        "df = sort_log(df,\n",
        "              timestamp)"
      ],
      "metadata": {
        "id": "mUm6ThK2wDXA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Debiasing and cleaning\n",
        "df = debiasing(df, end_date, max_duration,\n",
        "              case_id, timestamp)\n",
        "print(df.info())\n",
        "print(\"Number of retaining cases:\", df[case_id].nunique())"
      ],
      "metadata": {
        "id": "Dw6eG_60ighe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af4d46c-512d-49e5-9454-962c83404b3a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/preprocessing.py:71: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  case_stops_df['date'] = case_stops_df[timestamp].dt.to_period('M')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 216107 entries, 0 to 216106\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count   Dtype              \n",
            "---  ------             --------------   -----              \n",
            " 0   Unnamed: 0         216107 non-null  int64              \n",
            " 1   case:concept:name  216107 non-null  object             \n",
            " 2   time:timestamp     216107 non-null  datetime64[ns, UTC]\n",
            " 3   concept:name       216107 non-null  object             \n",
            "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
            "memory usage: 6.6+ MB\n",
            "None\n",
            "Number of retaining cases: 5711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Get rid of discard case\n",
        "df_no_discard = create_table_without_discard_case(df, test_ratio,\n",
        "                                                  case_id, timestamp)\n",
        "print(df_no_discard.info())\n",
        "print(\"Number of remaining cases:\", df_no_discard[case_id].nunique())\n",
        "print(\"Number of activity labels:\", df_no_discard[event_name].nunique())"
      ],
      "metadata": {
        "id": "dbyp5G5awG6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0fdbd3d-95a8-4254-d5e8-564c88595ad3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 158994 entries, 0 to 216106\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count   Dtype              \n",
            "---  ------             --------------   -----              \n",
            " 0   Unnamed: 0         158994 non-null  int64              \n",
            " 1   case:concept:name  158994 non-null  object             \n",
            " 2   time:timestamp     158994 non-null  datetime64[ns, UTC]\n",
            " 3   concept:name       158994 non-null  object             \n",
            "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
            "memory usage: 6.1+ MB\n",
            "None\n",
            "Number of remaining cases: 4123\n",
            "Number of activity labels: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Subset: retain dataframe only before training / test split.\n",
        "train_test_split_time, train_test_split_idx = get_train_test_split_point(df, test_ratio,\n",
        "                                                      case_id, timestamp)\n",
        "print(train_test_split_time)\n",
        "print(train_test_split_idx)"
      ],
      "metadata": {
        "id": "eZnfogilxNyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15534a36-9e87-4f67-e5e1-0be2ed516832"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2016-02-24 16:44:54.829000+00:00\n",
            "130497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_df = df_no_discard[df_no_discard[timestamp] < train_test_split_time]\n",
        "print(training_df.info())\n",
        "print(\"Number of cases in training set:\", training_df[case_id].nunique())\n",
        "print(\"Number of activity labels:\", training_df[event_name].nunique())"
      ],
      "metadata": {
        "id": "vhZLij__xX4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256f0619-d167-47e6-865d-7ef8e30093ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 95857 entries, 0 to 130450\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count  Dtype              \n",
            "---  ------             --------------  -----              \n",
            " 0   Unnamed: 0         95857 non-null  int64              \n",
            " 1   case:concept:name  95857 non-null  object             \n",
            " 2   time:timestamp     95857 non-null  datetime64[ns, UTC]\n",
            " 3   concept:name       95857 non-null  object             \n",
            "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
            "memory usage: 3.7+ MB\n",
            "None\n",
            "Number of cases in training set: 2409\n",
            "Number of activity labels: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Create time features\n",
        "training_df = create_time_features(training_df, case_id,timestamp)\n",
        "print(training_df.info())\n",
        "print(training_df.head(20))"
      ],
      "metadata": {
        "id": "f7RU4CMC9k5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0ef6c7-74da-429d-b4fd-efbef631d215"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 95857 entries, 0 to 95856\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count  Dtype              \n",
            "---  ------             --------------  -----              \n",
            " 0   Unnamed: 0         95857 non-null  int64              \n",
            " 1   case:concept:name  95857 non-null  object             \n",
            " 2   time:timestamp     95857 non-null  datetime64[ns, UTC]\n",
            " 3   concept:name       95857 non-null  object             \n",
            " 4   log_ts_pre         95857 non-null  float64            \n",
            " 5   trace_ts_pre       95857 non-null  float64            \n",
            " 6   trace_ts_start     95857 non-null  float64            \n",
            "dtypes: datetime64[ns, UTC](1), float64(3), int64(1), object(2)\n",
            "memory usage: 5.1+ MB\n",
            "None\n",
            "    Unnamed: 0       case:concept:name                   time:timestamp  \\\n",
            "0            0   Application_652823628 2016-01-01 09:51:15.304000+00:00   \n",
            "1            1   Application_652823628 2016-01-01 09:51:15.352000+00:00   \n",
            "2            2   Application_652823628 2016-01-01 09:51:15.774000+00:00   \n",
            "3            3   Application_652823628 2016-01-01 09:52:36.392000+00:00   \n",
            "4            4   Application_652823628 2016-01-01 09:52:36.403000+00:00   \n",
            "5            5   Application_652823628 2016-01-01 09:52:36.413000+00:00   \n",
            "6            6  Application_1691306052 2016-01-01 10:16:11.500000+00:00   \n",
            "7            7  Application_1691306052 2016-01-01 10:16:11.549000+00:00   \n",
            "8            8  Application_1691306052 2016-01-01 10:16:11.740000+00:00   \n",
            "9            9  Application_1691306052 2016-01-01 10:17:31.573000+00:00   \n",
            "10          10  Application_1691306052 2016-01-01 10:17:31.584000+00:00   \n",
            "11          11  Application_1691306052 2016-01-01 10:17:31.594000+00:00   \n",
            "12          12   Application_428409768 2016-01-01 11:19:38.177000+00:00   \n",
            "13          13   Application_428409768 2016-01-01 11:19:38.235000+00:00   \n",
            "14          14   Application_428409768 2016-01-01 11:19:38.914000+00:00   \n",
            "15          15   Application_428409768 2016-01-01 11:20:37.391000+00:00   \n",
            "16          16   Application_428409768 2016-01-01 11:20:37.409000+00:00   \n",
            "17          17   Application_428409768 2016-01-01 11:20:37.422000+00:00   \n",
            "18          18  Application_1746793196 2016-01-01 12:34:53.911000+00:00   \n",
            "19          19  Application_1746793196 2016-01-01 12:34:53.950000+00:00   \n",
            "\n",
            "              concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  \n",
            "0     A_Create Application       0.000         0.000           0.000  \n",
            "1              A_Submitted       0.048         0.048           0.048  \n",
            "2           W_Handle leads       0.422         0.422           0.470  \n",
            "3           W_Handle leads      80.618        80.618          81.088  \n",
            "4   W_Complete application       0.011         0.011          81.099  \n",
            "5                A_Concept       0.010         0.010          81.109  \n",
            "6     A_Create Application    1415.087         0.000           0.000  \n",
            "7              A_Submitted       0.049         0.049           0.049  \n",
            "8           W_Handle leads       0.191         0.191           0.240  \n",
            "9           W_Handle leads      79.833        79.833          80.073  \n",
            "10  W_Complete application       0.011         0.011          80.084  \n",
            "11               A_Concept       0.010         0.010          80.094  \n",
            "12    A_Create Application    3726.583         0.000           0.000  \n",
            "13             A_Submitted       0.058         0.058           0.058  \n",
            "14          W_Handle leads       0.679         0.679           0.737  \n",
            "15          W_Handle leads      58.477        58.477          59.214  \n",
            "16  W_Complete application       0.018         0.018          59.232  \n",
            "17               A_Concept       0.013         0.013          59.245  \n",
            "18    A_Create Application    4456.489         0.000           0.000  \n",
            "19             A_Submitted       0.039         0.039           0.039  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Standardize time features\n",
        "training_df, mean_dict, std_dict = train_standardize(training_df,\n",
        "                                                     continuous_features)\n",
        "print(training_df.head(20))\n",
        "print(mean_dict)\n",
        "print(std_dict)"
      ],
      "metadata": {
        "id": "i9MNzB3BjTJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f83aca-7d06-41ef-f582-e145f7230fad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Unnamed: 0       case:concept:name                   time:timestamp  \\\n",
            "0            0   Application_652823628 2016-01-01 09:51:15.304000+00:00   \n",
            "1            1   Application_652823628 2016-01-01 09:51:15.352000+00:00   \n",
            "2            2   Application_652823628 2016-01-01 09:51:15.774000+00:00   \n",
            "3            3   Application_652823628 2016-01-01 09:52:36.392000+00:00   \n",
            "4            4   Application_652823628 2016-01-01 09:52:36.403000+00:00   \n",
            "5            5   Application_652823628 2016-01-01 09:52:36.413000+00:00   \n",
            "6            6  Application_1691306052 2016-01-01 10:16:11.500000+00:00   \n",
            "7            7  Application_1691306052 2016-01-01 10:16:11.549000+00:00   \n",
            "8            8  Application_1691306052 2016-01-01 10:16:11.740000+00:00   \n",
            "9            9  Application_1691306052 2016-01-01 10:17:31.573000+00:00   \n",
            "10          10  Application_1691306052 2016-01-01 10:17:31.584000+00:00   \n",
            "11          11  Application_1691306052 2016-01-01 10:17:31.594000+00:00   \n",
            "12          12   Application_428409768 2016-01-01 11:19:38.177000+00:00   \n",
            "13          13   Application_428409768 2016-01-01 11:19:38.235000+00:00   \n",
            "14          14   Application_428409768 2016-01-01 11:19:38.914000+00:00   \n",
            "15          15   Application_428409768 2016-01-01 11:20:37.391000+00:00   \n",
            "16          16   Application_428409768 2016-01-01 11:20:37.409000+00:00   \n",
            "17          17   Application_428409768 2016-01-01 11:20:37.422000+00:00   \n",
            "18          18  Application_1746793196 2016-01-01 12:34:53.911000+00:00   \n",
            "19          19  Application_1746793196 2016-01-01 12:34:53.950000+00:00   \n",
            "\n",
            "              concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  \n",
            "0     A_Create Application   -0.070038     -0.214029       -0.903653  \n",
            "1              A_Submitted   -0.069970     -0.214029       -0.903653  \n",
            "2           W_Handle leads   -0.069434     -0.214027       -0.903652  \n",
            "3           W_Handle leads    0.045387     -0.213518       -0.903538  \n",
            "4   W_Complete application   -0.070023     -0.214029       -0.903538  \n",
            "5                A_Concept   -0.070024     -0.214029       -0.903538  \n",
            "6     A_Create Application    1.956020     -0.214029       -0.903653  \n",
            "7              A_Submitted   -0.069968     -0.214029       -0.903653  \n",
            "8           W_Handle leads   -0.069765     -0.214028       -0.903653  \n",
            "9           W_Handle leads    0.044263     -0.213523       -0.903539  \n",
            "10  W_Complete application   -0.070023     -0.214029       -0.903539  \n",
            "11               A_Concept   -0.070024     -0.214029       -0.903539  \n",
            "12    A_Create Application    5.265518     -0.214029       -0.903653  \n",
            "13             A_Submitted   -0.069955     -0.214029       -0.903653  \n",
            "14          W_Handle leads   -0.069066     -0.214025       -0.903652  \n",
            "15          W_Handle leads    0.013686     -0.213659       -0.903569  \n",
            "16  W_Complete application   -0.070013     -0.214029       -0.903569  \n",
            "17               A_Concept   -0.070020     -0.214029       -0.903569  \n",
            "18    A_Create Application    6.310565     -0.214029       -0.903653  \n",
            "19             A_Submitted   -0.069983     -0.214029       -0.903653  \n",
            "{'log_ts_pre': 48.917856964019315, 'trace_ts_pre': 33755.57912952627, 'trace_ts_start': 637852.0188574648}\n",
            "{'log_ts_pre': 698.4431794443758, 'trace_ts_pre': 157714.7383267489, 'trace_ts_start': 705859.5676935958}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Map case ID to numbers\n",
        "training_df, case_id_dict= mapping_case_id(training_df,\n",
        "                                     case_id)\n",
        "print(len(case_id_dict))\n",
        "print(training_df.head(20))"
      ],
      "metadata": {
        "id": "bchIX4N198He",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802c1d2c-19fd-4bff-ee22-4e50a5ced187"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2409\n",
            "    Unnamed: 0  case:concept:name                   time:timestamp  \\\n",
            "0            0                  1 2016-01-01 09:51:15.304000+00:00   \n",
            "1            1                  1 2016-01-01 09:51:15.352000+00:00   \n",
            "2            2                  1 2016-01-01 09:51:15.774000+00:00   \n",
            "3            3                  1 2016-01-01 09:52:36.392000+00:00   \n",
            "4            4                  1 2016-01-01 09:52:36.403000+00:00   \n",
            "5            5                  1 2016-01-01 09:52:36.413000+00:00   \n",
            "6            6                  2 2016-01-01 10:16:11.500000+00:00   \n",
            "7            7                  2 2016-01-01 10:16:11.549000+00:00   \n",
            "8            8                  2 2016-01-01 10:16:11.740000+00:00   \n",
            "9            9                  2 2016-01-01 10:17:31.573000+00:00   \n",
            "10          10                  2 2016-01-01 10:17:31.584000+00:00   \n",
            "11          11                  2 2016-01-01 10:17:31.594000+00:00   \n",
            "12          12                  3 2016-01-01 11:19:38.177000+00:00   \n",
            "13          13                  3 2016-01-01 11:19:38.235000+00:00   \n",
            "14          14                  3 2016-01-01 11:19:38.914000+00:00   \n",
            "15          15                  3 2016-01-01 11:20:37.391000+00:00   \n",
            "16          16                  3 2016-01-01 11:20:37.409000+00:00   \n",
            "17          17                  3 2016-01-01 11:20:37.422000+00:00   \n",
            "18          18                  4 2016-01-01 12:34:53.911000+00:00   \n",
            "19          19                  4 2016-01-01 12:34:53.950000+00:00   \n",
            "\n",
            "              concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  \n",
            "0     A_Create Application   -0.070038     -0.214029       -0.903653  \n",
            "1              A_Submitted   -0.069970     -0.214029       -0.903653  \n",
            "2           W_Handle leads   -0.069434     -0.214027       -0.903652  \n",
            "3           W_Handle leads    0.045387     -0.213518       -0.903538  \n",
            "4   W_Complete application   -0.070023     -0.214029       -0.903538  \n",
            "5                A_Concept   -0.070024     -0.214029       -0.903538  \n",
            "6     A_Create Application    1.956020     -0.214029       -0.903653  \n",
            "7              A_Submitted   -0.069968     -0.214029       -0.903653  \n",
            "8           W_Handle leads   -0.069765     -0.214028       -0.903653  \n",
            "9           W_Handle leads    0.044263     -0.213523       -0.903539  \n",
            "10  W_Complete application   -0.070023     -0.214029       -0.903539  \n",
            "11               A_Concept   -0.070024     -0.214029       -0.903539  \n",
            "12    A_Create Application    5.265518     -0.214029       -0.903653  \n",
            "13             A_Submitted   -0.069955     -0.214029       -0.903653  \n",
            "14          W_Handle leads   -0.069066     -0.214025       -0.903652  \n",
            "15          W_Handle leads    0.013686     -0.213659       -0.903569  \n",
            "16  W_Complete application   -0.070013     -0.214029       -0.903569  \n",
            "17               A_Concept   -0.070020     -0.214029       -0.903569  \n",
            "18    A_Create Application    6.310565     -0.214029       -0.903653  \n",
            "19             A_Submitted   -0.069983     -0.214029       -0.903653  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Insert SOC and EOC rows\n",
        "training_df = add_soc_eoc(training_df,\n",
        "                          case_id, timestamp, event_name)\n",
        "print(training_df.info())\n",
        "print(training_df.head(20))\n"
      ],
      "metadata": {
        "id": "Vs_xPKyf-TQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493c4c87-2277-4ed0-c626-32ed5363585b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100675 entries, 0 to 100674\n",
            "Data columns (total 8 columns):\n",
            " #   Column             Non-Null Count   Dtype              \n",
            "---  ------             --------------   -----              \n",
            " 0   Unnamed: 0         100675 non-null  int64              \n",
            " 1   case:concept:name  100675 non-null  int64              \n",
            " 2   time:timestamp     100675 non-null  datetime64[ns, UTC]\n",
            " 3   concept:name       100675 non-null  object             \n",
            " 4   log_ts_pre         100675 non-null  float64            \n",
            " 5   trace_ts_pre       100675 non-null  float64            \n",
            " 6   trace_ts_start     100675 non-null  float64            \n",
            " 7   event_idx          100675 non-null  int64              \n",
            "dtypes: datetime64[ns, UTC](1), float64(3), int64(3), object(1)\n",
            "memory usage: 6.1+ MB\n",
            "None\n",
            "    Unnamed: 0  case:concept:name                   time:timestamp  \\\n",
            "0            0                  1 2016-01-01 09:51:15.304000+00:00   \n",
            "1            0                  1 2016-01-01 09:51:15.304000+00:00   \n",
            "2            1                  1 2016-01-01 09:51:15.352000+00:00   \n",
            "3            2                  1 2016-01-01 09:51:15.774000+00:00   \n",
            "4            3                  1 2016-01-01 09:52:36.392000+00:00   \n",
            "5            4                  1 2016-01-01 09:52:36.403000+00:00   \n",
            "6            5                  1 2016-01-01 09:52:36.413000+00:00   \n",
            "7            6                  2 2016-01-01 10:16:11.500000+00:00   \n",
            "8            6                  2 2016-01-01 10:16:11.500000+00:00   \n",
            "9            7                  2 2016-01-01 10:16:11.549000+00:00   \n",
            "10           8                  2 2016-01-01 10:16:11.740000+00:00   \n",
            "11           9                  2 2016-01-01 10:17:31.573000+00:00   \n",
            "12          10                  2 2016-01-01 10:17:31.584000+00:00   \n",
            "13          11                  2 2016-01-01 10:17:31.594000+00:00   \n",
            "14          12                  3 2016-01-01 11:19:38.177000+00:00   \n",
            "15          12                  3 2016-01-01 11:19:38.177000+00:00   \n",
            "16          13                  3 2016-01-01 11:19:38.235000+00:00   \n",
            "17          14                  3 2016-01-01 11:19:38.914000+00:00   \n",
            "18          15                  3 2016-01-01 11:20:37.391000+00:00   \n",
            "19          16                  3 2016-01-01 11:20:37.409000+00:00   \n",
            "\n",
            "              concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  \\\n",
            "0                      SOC   -0.070038     -0.214029       -0.903653   \n",
            "1     A_Create Application   -0.070038     -0.214029       -0.903653   \n",
            "2              A_Submitted   -0.069970     -0.214029       -0.903653   \n",
            "3           W_Handle leads   -0.069434     -0.214027       -0.903652   \n",
            "4           W_Handle leads    0.045387     -0.213518       -0.903538   \n",
            "5   W_Complete application   -0.070023     -0.214029       -0.903538   \n",
            "6                A_Concept   -0.070024     -0.214029       -0.903538   \n",
            "7                      SOC    1.956020     -0.214029       -0.903653   \n",
            "8     A_Create Application    1.956020     -0.214029       -0.903653   \n",
            "9              A_Submitted   -0.069968     -0.214029       -0.903653   \n",
            "10          W_Handle leads   -0.069765     -0.214028       -0.903653   \n",
            "11          W_Handle leads    0.044263     -0.213523       -0.903539   \n",
            "12  W_Complete application   -0.070023     -0.214029       -0.903539   \n",
            "13               A_Concept   -0.070024     -0.214029       -0.903539   \n",
            "14                     SOC    5.265518     -0.214029       -0.903653   \n",
            "15    A_Create Application    5.265518     -0.214029       -0.903653   \n",
            "16             A_Submitted   -0.069955     -0.214029       -0.903653   \n",
            "17          W_Handle leads   -0.069066     -0.214025       -0.903652   \n",
            "18          W_Handle leads    0.013686     -0.213659       -0.903569   \n",
            "19  W_Complete application   -0.070013     -0.214029       -0.903569   \n",
            "\n",
            "    event_idx  \n",
            "0           1  \n",
            "1           2  \n",
            "2           3  \n",
            "3           4  \n",
            "4           5  \n",
            "5           6  \n",
            "6           7  \n",
            "7           8  \n",
            "8           9  \n",
            "9          10  \n",
            "10         11  \n",
            "11         12  \n",
            "12         13  \n",
            "13         14  \n",
            "14         15  \n",
            "15         16  \n",
            "16         17  \n",
            "17         18  \n",
            "18         19  \n",
            "19         20  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Mapping event name to numbers\n",
        "training_df, train_event_name_dict = train_mapping_event_name(training_df,\n",
        "                                                                  event_name)\n",
        "print(training_df.head(20))\n",
        "print(train_event_name_dict)"
      ],
      "metadata": {
        "id": "ObdaRNyD-cVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7995a3d4-4be4-4c81-cabe-08769109ab9c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Unnamed: 0  case:concept:name                   time:timestamp  \\\n",
            "0            0                  1 2016-01-01 09:51:15.304000+00:00   \n",
            "1            0                  1 2016-01-01 09:51:15.304000+00:00   \n",
            "2            1                  1 2016-01-01 09:51:15.352000+00:00   \n",
            "3            2                  1 2016-01-01 09:51:15.774000+00:00   \n",
            "4            3                  1 2016-01-01 09:52:36.392000+00:00   \n",
            "5            4                  1 2016-01-01 09:52:36.403000+00:00   \n",
            "6            5                  1 2016-01-01 09:52:36.413000+00:00   \n",
            "7            6                  2 2016-01-01 10:16:11.500000+00:00   \n",
            "8            6                  2 2016-01-01 10:16:11.500000+00:00   \n",
            "9            7                  2 2016-01-01 10:16:11.549000+00:00   \n",
            "10           8                  2 2016-01-01 10:16:11.740000+00:00   \n",
            "11           9                  2 2016-01-01 10:17:31.573000+00:00   \n",
            "12          10                  2 2016-01-01 10:17:31.584000+00:00   \n",
            "13          11                  2 2016-01-01 10:17:31.594000+00:00   \n",
            "14          12                  3 2016-01-01 11:19:38.177000+00:00   \n",
            "15          12                  3 2016-01-01 11:19:38.177000+00:00   \n",
            "16          13                  3 2016-01-01 11:19:38.235000+00:00   \n",
            "17          14                  3 2016-01-01 11:19:38.914000+00:00   \n",
            "18          15                  3 2016-01-01 11:20:37.391000+00:00   \n",
            "19          16                  3 2016-01-01 11:20:37.409000+00:00   \n",
            "\n",
            "    concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  event_idx  \n",
            "0              2   -0.070038     -0.214029       -0.903653          1  \n",
            "1              4   -0.070038     -0.214029       -0.903653          2  \n",
            "2              5   -0.069970     -0.214029       -0.903653          3  \n",
            "3              6   -0.069434     -0.214027       -0.903652          4  \n",
            "4              6    0.045387     -0.213518       -0.903538          5  \n",
            "5              7   -0.070023     -0.214029       -0.903538          6  \n",
            "6              8   -0.070024     -0.214029       -0.903538          7  \n",
            "7              2    1.956020     -0.214029       -0.903653          8  \n",
            "8              4    1.956020     -0.214029       -0.903653          9  \n",
            "9              5   -0.069968     -0.214029       -0.903653         10  \n",
            "10             6   -0.069765     -0.214028       -0.903653         11  \n",
            "11             6    0.044263     -0.213523       -0.903539         12  \n",
            "12             7   -0.070023     -0.214029       -0.903539         13  \n",
            "13             8   -0.070024     -0.214029       -0.903539         14  \n",
            "14             2    5.265518     -0.214029       -0.903653         15  \n",
            "15             4    5.265518     -0.214029       -0.903653         16  \n",
            "16             5   -0.069955     -0.214029       -0.903653         17  \n",
            "17             6   -0.069066     -0.214025       -0.903652         18  \n",
            "18             6    0.013686     -0.213659       -0.903569         19  \n",
            "19             7   -0.070013     -0.214029       -0.903569         20  \n",
            "{'SOC': 2, 'EOC': 3, 'A_Create Application': 4, 'A_Submitted': 5, 'W_Handle leads': 6, 'W_Complete application': 7, 'A_Concept': 8, 'A_Accepted': 9, 'O_Create Offer': 10, 'O_Created': 11, 'O_Sent (mail and online)': 12, 'W_Call after offers': 13, 'A_Complete': 14, 'O_Cancelled': 15, 'W_Validate application': 16, 'A_Validating': 17, 'O_Returned': 18, 'O_Sent (online only)': 19, 'W_Call incomplete files': 20, 'A_Incomplete': 21, 'A_Cancelled': 22, 'O_Accepted': 23, 'A_Pending': 24, 'A_Denied': 25, 'O_Refused': 26, 'W_Assess potential fraud': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set printed tensor format\n",
        "torch.set_printoptions(sci_mode=False, precision=2)"
      ],
      "metadata": {
        "id": "xVRwx1dPkb9w"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of train_log_prefix_tensor\n",
        "\n",
        "98266 - Number of events in training set used for creating log prefix (i.e. number of events excluding EOC)\n",
        "\n",
        "30 - Length of log prefix\n",
        "\n",
        "29 - dimension of one-hot encoding (i.e. num_act, which is 28) + number of time features (which is 1 for log prefix)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YeHlUEmEXA2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Create train_log_prefix_tensor, train_trace_prefix_tensor, train_suffix_act_tensor, train_suffix_time_tensor\n",
        "train_log_prefix_tensor = create_log_prefix_tensor(training_df, log_prefix_length, set_name, test_ratio, num_act,\n",
        "                                                       log_col_name, categorical_features, case_id, timestamp, event_name)\n",
        "print(train_log_prefix_tensor.shape)\n",
        "print(train_log_prefix_tensor[:5])"
      ],
      "metadata": {
        "id": "LgKtu_Lt-vHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da8125fe-34d1-4426-cd0a-613202956f0a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([98266, 30, 29])\n",
            "tensor([[[     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      1.00,  ...,      0.00,      0.00,\n",
            "              -0.07]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      1.00,  ...,      0.00,      0.00,\n",
            "              -0.07],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "              -0.07]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      1.00,  ...,      0.00,      0.00,\n",
            "              -0.07],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "              -0.07],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "              -0.07]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "              -0.07],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "              -0.07],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "              -0.07]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "              -0.07],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "              -0.07],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,      0.00,\n",
            "               0.05]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of train_trace_prefix_tensor\n",
        "\n",
        "98266 - Number of events in training set used for creating trace prefix (i.e. number of events excluding EOC)\n",
        "\n",
        "15 - Length of trace prefix\n",
        "\n",
        "30 - dimension of one-hot encoding (i.e. num_act, which is 28) + number of time features (which is 2 for trace prefix)"
      ],
      "metadata": {
        "id": "HAD1GTrMpFVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_trace_prefix_tensor = create_trace_prefix_tensor(training_df, trace_prefix_length, set_name, test_ratio, num_act,\n",
        "                                                           trace_prefix_col_name, categorical_features, event_idx, case_id, timestamp, event_name)\n",
        "print(train_trace_prefix_tensor.shape)\n",
        "print(train_trace_prefix_tensor[:5])"
      ],
      "metadata": {
        "id": "206KoGTe_KPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1731c40-029a-47a8-dc34-d5623414cfe6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([98266, 15, 30])\n",
            "tensor([[[     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      1.00,  ...,      0.00,     -0.90,\n",
            "              -0.21]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      1.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      1.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of train_suffix_act_tensor\n",
        "\n",
        "98266 - Number of events in training set used for creating suffix (i.e. number of events excluding EOC)\n",
        "\n",
        "35 - Length of suffix"
      ],
      "metadata": {
        "id": "uKwQcHaioc9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_suffix_act_tensor, train_suffix_time_tensor = create_trace_suffix_tensor(training_df, trace_suffix_length, set_name, test_ratio,\n",
        "                                                                                   trace_suffix_col_name, categorical_features, event_idx, case_id, timestamp, event_name)\n",
        "print(train_suffix_act_tensor.shape)\n",
        "print(train_suffix_act_tensor[:5])\n"
      ],
      "metadata": {
        "id": "SJ1mpUftA0c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476660ea-0f4a-4a47-b673-1786397180e5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([98266, 35])\n",
            "tensor([[ 4,  5,  6,  6,  7,  8,  7,  7,  9, 10, 11, 12,  7, 13, 13, 14, 13, 13,\n",
            "         13, 13, 16, 16, 17, 18, 16, 16, 20, 20, 21, 20, 20, 20, 20, 16, 16],\n",
            "        [ 5,  6,  6,  7,  8,  7,  7,  9, 10, 11, 12,  7, 13, 13, 14, 13, 13, 13,\n",
            "         13, 16, 16, 17, 18, 16, 16, 20, 20, 21, 20, 20, 20, 20, 16, 16, 17],\n",
            "        [ 6,  6,  7,  8,  7,  7,  9, 10, 11, 12,  7, 13, 13, 14, 13, 13, 13, 13,\n",
            "         16, 16, 17, 18, 16, 16, 20, 20, 21, 20, 20, 20, 20, 16, 16, 17, 16],\n",
            "        [ 6,  7,  8,  7,  7,  9, 10, 11, 12,  7, 13, 13, 14, 13, 13, 13, 13, 16,\n",
            "         16, 17, 18, 16, 16, 20, 20, 21, 20, 20, 20, 20, 16, 16, 17, 16, 23],\n",
            "        [ 7,  8,  7,  7,  9, 10, 11, 12,  7, 13, 13, 14, 13, 13, 13, 13, 16, 16,\n",
            "         17, 18, 16, 16, 20, 20, 21, 20, 20, 20, 20, 16, 16, 17, 16, 23, 24]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_suffix_time_tensor.shape)\n",
        "print(train_suffix_time_tensor[:5])"
      ],
      "metadata": {
        "id": "0aNsOhnfkvRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adcfb8da-6680-4ed1-de3b-58ccb2cc34b3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([98266, 35])\n",
            "tensor([[-0.21, -0.21, -0.21, -0.21, -0.21, -0.21,  0.35, -0.21, -0.20, -0.21,\n",
            "         -0.21, -0.21, -0.21, -0.21, -0.21, -0.21, -0.21,  1.93, -0.21,  3.71,\n",
            "         -0.21, -0.21, -0.21, -0.21, -0.21,  0.24, -0.21, -0.21, -0.21, -0.21,\n",
            "         -0.16, -0.21, -0.16, -0.21, -0.21],\n",
            "        [-0.21, -0.21, -0.21, -0.21, -0.21,  0.35, -0.21, -0.20, -0.21, -0.21,\n",
            "         -0.21, -0.21, -0.21, -0.21, -0.21, -0.21,  1.93, -0.21,  3.71, -0.21,\n",
            "         -0.21, -0.21, -0.21, -0.21,  0.24, -0.21, -0.21, -0.21, -0.21, -0.16,\n",
            "         -0.21, -0.16, -0.21, -0.21, -0.21],\n",
            "        [-0.21, -0.21, -0.21, -0.21,  0.35, -0.21, -0.20, -0.21, -0.21, -0.21,\n",
            "         -0.21, -0.21, -0.21, -0.21, -0.21,  1.93, -0.21,  3.71, -0.21, -0.21,\n",
            "         -0.21, -0.21, -0.21,  0.24, -0.21, -0.21, -0.21, -0.21, -0.16, -0.21,\n",
            "         -0.16, -0.21, -0.21, -0.21, -0.21],\n",
            "        [-0.21, -0.21, -0.21,  0.35, -0.21, -0.20, -0.21, -0.21, -0.21, -0.21,\n",
            "         -0.21, -0.21, -0.21, -0.21,  1.93, -0.21,  3.71, -0.21, -0.21, -0.21,\n",
            "         -0.21, -0.21,  0.24, -0.21, -0.21, -0.21, -0.21, -0.16, -0.21, -0.16,\n",
            "         -0.21, -0.21, -0.21, -0.21, -0.17],\n",
            "        [-0.21, -0.21,  0.35, -0.21, -0.20, -0.21, -0.21, -0.21, -0.21, -0.21,\n",
            "         -0.21, -0.21, -0.21,  1.93, -0.21,  3.71, -0.21, -0.21, -0.21, -0.21,\n",
            "         -0.21,  0.24, -0.21, -0.21, -0.21, -0.21, -0.16, -0.21, -0.16, -0.21,\n",
            "         -0.21, -0.21, -0.21, -0.17, -0.21]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Build TensorDataset\n",
        "train_dataset = TensorDataset(train_log_prefix_tensor, train_trace_prefix_tensor, train_suffix_act_tensor, train_suffix_time_tensor)"
      ],
      "metadata": {
        "id": "BjBJ4PWzByj6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Split TensorDataset into train_dataset, valid_dataset\n",
        "train_dataset, valid_dataset = random_split(train_dataset, [1-validation_ratio, validation_ratio])\n",
        "print(len(train_dataset))\n",
        "print(len(valid_dataset))"
      ],
      "metadata": {
        "id": "iFg_-9cHk5u8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf54512-c023-4156-b38c-c42c6a4d405b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78613\n",
            "19653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Build train_dataloader, valid_dataloader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "SPQFmrMek1UX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create test dataloader pipeline\n",
        "The steps in this section mirror the steps in the function *create_test_dataloader* from *dataloader_pipeline*\n",
        "\n",
        "The steps are executed separately to allow for inspection of intermediate results."
      ],
      "metadata": {
        "id": "jSUVnaonlOdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "csv_path = 'BPIC2017_6000cases.csv'\n",
        "end_date = '2017-01'\n",
        "max_duration = 47.81\n",
        "test_ratio = 0.3\n",
        "log_prefix_length = 30\n",
        "trace_prefix_length = 15\n",
        "trace_suffix_length = 35\n",
        "num_act = 28 # number of activity labels in training set: 24"
      ],
      "metadata": {
        "id": "vSeAUytelOLR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_name = 'test'\n",
        "log_col_name = ['concept:name', 'log_ts_pre']\n",
        "trace_prefix_col_name = ['concept:name', 'trace_ts_start', 'trace_ts_pre']\n",
        "trace_suffix_col_name = ['concept:name', 'trace_ts_pre']\n",
        "categorical_features = ['concept:name']\n",
        "continuous_features = ['log_ts_pre', 'trace_ts_pre', 'trace_ts_start']\n",
        "case_id = 'case:concept:name'\n",
        "timestamp = 'time:timestamp'\n",
        "event_name = 'concept:name'\n",
        "event_idx = 'event_idx'"
      ],
      "metadata": {
        "id": "A2J7eTerlsyW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_event_name_dict = train_event_name_dict\n",
        "mean_dict = mean_dict\n",
        "std_dict = std_dict"
      ],
      "metadata": {
        "id": "GX67pceglg1q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Tranform csv to dataframe\n",
        "df = pd.read_csv(csv_path)\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "OSSYXmVAl2jL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29965e2-327d-4b83-d819-b378c6d73e15"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 230225 entries, 0 to 230224\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count   Dtype \n",
            "---  ------             --------------   ----- \n",
            " 0   Unnamed: 0         230225 non-null  int64 \n",
            " 1   case:concept:name  230225 non-null  object\n",
            " 2   time:timestamp     230225 non-null  object\n",
            " 3   concept:name       230225 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 7.0+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Sort dataframe by timestamp\n",
        "df = sort_log(df,\n",
        "              timestamp)"
      ],
      "metadata": {
        "id": "bgPeKZ84mDX8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Debiasing and cleaning\n",
        "df = debiasing(df,end_date, max_duration,\n",
        "                   case_id, timestamp)\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "sr-3Futvl_CE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af14aabb-365f-401d-9758-c8eadb0c0026"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 216107 entries, 0 to 216106\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count   Dtype              \n",
            "---  ------             --------------   -----              \n",
            " 0   Unnamed: 0         216107 non-null  int64              \n",
            " 1   case:concept:name  216107 non-null  object             \n",
            " 2   time:timestamp     216107 non-null  datetime64[ns, UTC]\n",
            " 3   concept:name       216107 non-null  object             \n",
            "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
            "memory usage: 6.6+ MB\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/preprocessing.py:71: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  case_stops_df['date'] = case_stops_df[timestamp].dt.to_period('M')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Create time features\n",
        "df = create_time_features(df,\n",
        "                          case_id,timestamp)\n",
        "print(df.info())\n",
        "print(df.head(20))"
      ],
      "metadata": {
        "id": "bo1RuYSSmFiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e2d1de-f8be-4458-d3c0-1a4430814c93"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 216107 entries, 0 to 216106\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count   Dtype              \n",
            "---  ------             --------------   -----              \n",
            " 0   Unnamed: 0         216107 non-null  int64              \n",
            " 1   case:concept:name  216107 non-null  object             \n",
            " 2   time:timestamp     216107 non-null  datetime64[ns, UTC]\n",
            " 3   concept:name       216107 non-null  object             \n",
            " 4   log_ts_pre         216107 non-null  float64            \n",
            " 5   trace_ts_pre       216107 non-null  float64            \n",
            " 6   trace_ts_start     216107 non-null  float64            \n",
            "dtypes: datetime64[ns, UTC](1), float64(3), int64(1), object(2)\n",
            "memory usage: 11.5+ MB\n",
            "None\n",
            "    Unnamed: 0       case:concept:name                   time:timestamp  \\\n",
            "0            0   Application_652823628 2016-01-01 09:51:15.304000+00:00   \n",
            "1            1   Application_652823628 2016-01-01 09:51:15.352000+00:00   \n",
            "2            2   Application_652823628 2016-01-01 09:51:15.774000+00:00   \n",
            "3            3   Application_652823628 2016-01-01 09:52:36.392000+00:00   \n",
            "4            4   Application_652823628 2016-01-01 09:52:36.403000+00:00   \n",
            "5            5   Application_652823628 2016-01-01 09:52:36.413000+00:00   \n",
            "6            6  Application_1691306052 2016-01-01 10:16:11.500000+00:00   \n",
            "7            7  Application_1691306052 2016-01-01 10:16:11.549000+00:00   \n",
            "8            8  Application_1691306052 2016-01-01 10:16:11.740000+00:00   \n",
            "9            9  Application_1691306052 2016-01-01 10:17:31.573000+00:00   \n",
            "10          10  Application_1691306052 2016-01-01 10:17:31.584000+00:00   \n",
            "11          11  Application_1691306052 2016-01-01 10:17:31.594000+00:00   \n",
            "12          12   Application_428409768 2016-01-01 11:19:38.177000+00:00   \n",
            "13          13   Application_428409768 2016-01-01 11:19:38.235000+00:00   \n",
            "14          14   Application_428409768 2016-01-01 11:19:38.914000+00:00   \n",
            "15          15   Application_428409768 2016-01-01 11:20:37.391000+00:00   \n",
            "16          16   Application_428409768 2016-01-01 11:20:37.409000+00:00   \n",
            "17          17   Application_428409768 2016-01-01 11:20:37.422000+00:00   \n",
            "18          18  Application_1746793196 2016-01-01 12:34:53.911000+00:00   \n",
            "19          19  Application_1746793196 2016-01-01 12:34:53.950000+00:00   \n",
            "\n",
            "              concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  \n",
            "0     A_Create Application       0.000         0.000           0.000  \n",
            "1              A_Submitted       0.048         0.048           0.048  \n",
            "2           W_Handle leads       0.422         0.422           0.470  \n",
            "3           W_Handle leads      80.618        80.618          81.088  \n",
            "4   W_Complete application       0.011         0.011          81.099  \n",
            "5                A_Concept       0.010         0.010          81.109  \n",
            "6     A_Create Application    1415.087         0.000           0.000  \n",
            "7              A_Submitted       0.049         0.049           0.049  \n",
            "8           W_Handle leads       0.191         0.191           0.240  \n",
            "9           W_Handle leads      79.833        79.833          80.073  \n",
            "10  W_Complete application       0.011         0.011          80.084  \n",
            "11               A_Concept       0.010         0.010          80.094  \n",
            "12    A_Create Application    3726.583         0.000           0.000  \n",
            "13             A_Submitted       0.058         0.058           0.058  \n",
            "14          W_Handle leads       0.679         0.679           0.737  \n",
            "15          W_Handle leads      58.477        58.477          59.214  \n",
            "16  W_Complete application       0.018         0.018          59.232  \n",
            "17               A_Concept       0.013         0.013          59.245  \n",
            "18    A_Create Application    4456.489         0.000           0.000  \n",
            "19             A_Submitted       0.039         0.039           0.039  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Standardize time features\n",
        "df = test_standardize(df,\n",
        "                      mean_dict, std_dict, continuous_features)\n",
        "print(df.head(20))"
      ],
      "metadata": {
        "id": "_kqRB9W_mJGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269ad73f-c29f-4070-bdde-a4cdc391360f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Unnamed: 0       case:concept:name                   time:timestamp  \\\n",
            "0            0   Application_652823628 2016-01-01 09:51:15.304000+00:00   \n",
            "1            1   Application_652823628 2016-01-01 09:51:15.352000+00:00   \n",
            "2            2   Application_652823628 2016-01-01 09:51:15.774000+00:00   \n",
            "3            3   Application_652823628 2016-01-01 09:52:36.392000+00:00   \n",
            "4            4   Application_652823628 2016-01-01 09:52:36.403000+00:00   \n",
            "5            5   Application_652823628 2016-01-01 09:52:36.413000+00:00   \n",
            "6            6  Application_1691306052 2016-01-01 10:16:11.500000+00:00   \n",
            "7            7  Application_1691306052 2016-01-01 10:16:11.549000+00:00   \n",
            "8            8  Application_1691306052 2016-01-01 10:16:11.740000+00:00   \n",
            "9            9  Application_1691306052 2016-01-01 10:17:31.573000+00:00   \n",
            "10          10  Application_1691306052 2016-01-01 10:17:31.584000+00:00   \n",
            "11          11  Application_1691306052 2016-01-01 10:17:31.594000+00:00   \n",
            "12          12   Application_428409768 2016-01-01 11:19:38.177000+00:00   \n",
            "13          13   Application_428409768 2016-01-01 11:19:38.235000+00:00   \n",
            "14          14   Application_428409768 2016-01-01 11:19:38.914000+00:00   \n",
            "15          15   Application_428409768 2016-01-01 11:20:37.391000+00:00   \n",
            "16          16   Application_428409768 2016-01-01 11:20:37.409000+00:00   \n",
            "17          17   Application_428409768 2016-01-01 11:20:37.422000+00:00   \n",
            "18          18  Application_1746793196 2016-01-01 12:34:53.911000+00:00   \n",
            "19          19  Application_1746793196 2016-01-01 12:34:53.950000+00:00   \n",
            "\n",
            "              concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  \n",
            "0     A_Create Application   -0.070038     -0.214029       -0.903653  \n",
            "1              A_Submitted   -0.069970     -0.214029       -0.903653  \n",
            "2           W_Handle leads   -0.069434     -0.214027       -0.903652  \n",
            "3           W_Handle leads    0.045387     -0.213518       -0.903538  \n",
            "4   W_Complete application   -0.070023     -0.214029       -0.903538  \n",
            "5                A_Concept   -0.070024     -0.214029       -0.903538  \n",
            "6     A_Create Application    1.956020     -0.214029       -0.903653  \n",
            "7              A_Submitted   -0.069968     -0.214029       -0.903653  \n",
            "8           W_Handle leads   -0.069765     -0.214028       -0.903653  \n",
            "9           W_Handle leads    0.044263     -0.213523       -0.903539  \n",
            "10  W_Complete application   -0.070023     -0.214029       -0.903539  \n",
            "11               A_Concept   -0.070024     -0.214029       -0.903539  \n",
            "12    A_Create Application    5.265518     -0.214029       -0.903653  \n",
            "13             A_Submitted   -0.069955     -0.214029       -0.903653  \n",
            "14          W_Handle leads   -0.069066     -0.214025       -0.903652  \n",
            "15          W_Handle leads    0.013686     -0.213659       -0.903569  \n",
            "16  W_Complete application   -0.070013     -0.214029       -0.903569  \n",
            "17               A_Concept   -0.070020     -0.214029       -0.903569  \n",
            "18    A_Create Application    6.310565     -0.214029       -0.903653  \n",
            "19             A_Submitted   -0.069983     -0.214029       -0.903653  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Map case ID to numbers\n",
        "df, case_id_dict = mapping_case_id(df,\n",
        "                        case_id)\n",
        "print(len(case_id_dict))\n",
        "print(df.head(20))"
      ],
      "metadata": {
        "id": "4R8cWEkimLb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb26f66-0b22-4d9d-a5cf-85ecdd4b3073"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5711\n",
            "    Unnamed: 0  case:concept:name                   time:timestamp  \\\n",
            "0            0                  1 2016-01-01 09:51:15.304000+00:00   \n",
            "1            1                  1 2016-01-01 09:51:15.352000+00:00   \n",
            "2            2                  1 2016-01-01 09:51:15.774000+00:00   \n",
            "3            3                  1 2016-01-01 09:52:36.392000+00:00   \n",
            "4            4                  1 2016-01-01 09:52:36.403000+00:00   \n",
            "5            5                  1 2016-01-01 09:52:36.413000+00:00   \n",
            "6            6                  2 2016-01-01 10:16:11.500000+00:00   \n",
            "7            7                  2 2016-01-01 10:16:11.549000+00:00   \n",
            "8            8                  2 2016-01-01 10:16:11.740000+00:00   \n",
            "9            9                  2 2016-01-01 10:17:31.573000+00:00   \n",
            "10          10                  2 2016-01-01 10:17:31.584000+00:00   \n",
            "11          11                  2 2016-01-01 10:17:31.594000+00:00   \n",
            "12          12                  3 2016-01-01 11:19:38.177000+00:00   \n",
            "13          13                  3 2016-01-01 11:19:38.235000+00:00   \n",
            "14          14                  3 2016-01-01 11:19:38.914000+00:00   \n",
            "15          15                  3 2016-01-01 11:20:37.391000+00:00   \n",
            "16          16                  3 2016-01-01 11:20:37.409000+00:00   \n",
            "17          17                  3 2016-01-01 11:20:37.422000+00:00   \n",
            "18          18                  4 2016-01-01 12:34:53.911000+00:00   \n",
            "19          19                  4 2016-01-01 12:34:53.950000+00:00   \n",
            "\n",
            "              concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  \n",
            "0     A_Create Application   -0.070038     -0.214029       -0.903653  \n",
            "1              A_Submitted   -0.069970     -0.214029       -0.903653  \n",
            "2           W_Handle leads   -0.069434     -0.214027       -0.903652  \n",
            "3           W_Handle leads    0.045387     -0.213518       -0.903538  \n",
            "4   W_Complete application   -0.070023     -0.214029       -0.903538  \n",
            "5                A_Concept   -0.070024     -0.214029       -0.903538  \n",
            "6     A_Create Application    1.956020     -0.214029       -0.903653  \n",
            "7              A_Submitted   -0.069968     -0.214029       -0.903653  \n",
            "8           W_Handle leads   -0.069765     -0.214028       -0.903653  \n",
            "9           W_Handle leads    0.044263     -0.213523       -0.903539  \n",
            "10  W_Complete application   -0.070023     -0.214029       -0.903539  \n",
            "11               A_Concept   -0.070024     -0.214029       -0.903539  \n",
            "12    A_Create Application    5.265518     -0.214029       -0.903653  \n",
            "13             A_Submitted   -0.069955     -0.214029       -0.903653  \n",
            "14          W_Handle leads   -0.069066     -0.214025       -0.903652  \n",
            "15          W_Handle leads    0.013686     -0.213659       -0.903569  \n",
            "16  W_Complete application   -0.070013     -0.214029       -0.903569  \n",
            "17               A_Concept   -0.070020     -0.214029       -0.903569  \n",
            "18    A_Create Application    6.310565     -0.214029       -0.903653  \n",
            "19             A_Submitted   -0.069983     -0.214029       -0.903653  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Insert SOC and EOC rows\n",
        "df = add_soc_eoc(df,\n",
        "                  case_id, timestamp, event_name)\n",
        "print(df.info())\n",
        "print(df.head(20))"
      ],
      "metadata": {
        "id": "AIWkZNqtmprQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066fde02-4e94-47c4-fea0-bf963faf9d15"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 227529 entries, 0 to 227528\n",
            "Data columns (total 8 columns):\n",
            " #   Column             Non-Null Count   Dtype              \n",
            "---  ------             --------------   -----              \n",
            " 0   Unnamed: 0         227529 non-null  int64              \n",
            " 1   case:concept:name  227529 non-null  int64              \n",
            " 2   time:timestamp     227529 non-null  datetime64[ns, UTC]\n",
            " 3   concept:name       227529 non-null  object             \n",
            " 4   log_ts_pre         227529 non-null  float64            \n",
            " 5   trace_ts_pre       227529 non-null  float64            \n",
            " 6   trace_ts_start     227529 non-null  float64            \n",
            " 7   event_idx          227529 non-null  int64              \n",
            "dtypes: datetime64[ns, UTC](1), float64(3), int64(3), object(1)\n",
            "memory usage: 13.9+ MB\n",
            "None\n",
            "    Unnamed: 0  case:concept:name                   time:timestamp  \\\n",
            "0            0                  1 2016-01-01 09:51:15.304000+00:00   \n",
            "1            0                  1 2016-01-01 09:51:15.304000+00:00   \n",
            "2            1                  1 2016-01-01 09:51:15.352000+00:00   \n",
            "3            2                  1 2016-01-01 09:51:15.774000+00:00   \n",
            "4            3                  1 2016-01-01 09:52:36.392000+00:00   \n",
            "5            4                  1 2016-01-01 09:52:36.403000+00:00   \n",
            "6            5                  1 2016-01-01 09:52:36.413000+00:00   \n",
            "7            6                  2 2016-01-01 10:16:11.500000+00:00   \n",
            "8            6                  2 2016-01-01 10:16:11.500000+00:00   \n",
            "9            7                  2 2016-01-01 10:16:11.549000+00:00   \n",
            "10           8                  2 2016-01-01 10:16:11.740000+00:00   \n",
            "11           9                  2 2016-01-01 10:17:31.573000+00:00   \n",
            "12          10                  2 2016-01-01 10:17:31.584000+00:00   \n",
            "13          11                  2 2016-01-01 10:17:31.594000+00:00   \n",
            "14          12                  3 2016-01-01 11:19:38.177000+00:00   \n",
            "15          12                  3 2016-01-01 11:19:38.177000+00:00   \n",
            "16          13                  3 2016-01-01 11:19:38.235000+00:00   \n",
            "17          14                  3 2016-01-01 11:19:38.914000+00:00   \n",
            "18          15                  3 2016-01-01 11:20:37.391000+00:00   \n",
            "19          16                  3 2016-01-01 11:20:37.409000+00:00   \n",
            "\n",
            "              concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  \\\n",
            "0                      SOC   -0.070038     -0.214029       -0.903653   \n",
            "1     A_Create Application   -0.070038     -0.214029       -0.903653   \n",
            "2              A_Submitted   -0.069970     -0.214029       -0.903653   \n",
            "3           W_Handle leads   -0.069434     -0.214027       -0.903652   \n",
            "4           W_Handle leads    0.045387     -0.213518       -0.903538   \n",
            "5   W_Complete application   -0.070023     -0.214029       -0.903538   \n",
            "6                A_Concept   -0.070024     -0.214029       -0.903538   \n",
            "7                      SOC    1.956020     -0.214029       -0.903653   \n",
            "8     A_Create Application    1.956020     -0.214029       -0.903653   \n",
            "9              A_Submitted   -0.069968     -0.214029       -0.903653   \n",
            "10          W_Handle leads   -0.069765     -0.214028       -0.903653   \n",
            "11          W_Handle leads    0.044263     -0.213523       -0.903539   \n",
            "12  W_Complete application   -0.070023     -0.214029       -0.903539   \n",
            "13               A_Concept   -0.070024     -0.214029       -0.903539   \n",
            "14                     SOC    5.265518     -0.214029       -0.903653   \n",
            "15    A_Create Application    5.265518     -0.214029       -0.903653   \n",
            "16             A_Submitted   -0.069955     -0.214029       -0.903653   \n",
            "17          W_Handle leads   -0.069066     -0.214025       -0.903652   \n",
            "18          W_Handle leads    0.013686     -0.213659       -0.903569   \n",
            "19  W_Complete application   -0.070013     -0.214029       -0.903569   \n",
            "\n",
            "    event_idx  \n",
            "0           1  \n",
            "1           2  \n",
            "2           3  \n",
            "3           4  \n",
            "4           5  \n",
            "5           6  \n",
            "6           7  \n",
            "7           8  \n",
            "8           9  \n",
            "9          10  \n",
            "10         11  \n",
            "11         12  \n",
            "12         13  \n",
            "13         14  \n",
            "14         15  \n",
            "15         16  \n",
            "16         17  \n",
            "17         18  \n",
            "18         19  \n",
            "19         20  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Mapping event name to numbers\n",
        "df, test_event_name_dict = test_mapping_event_name(df, train_event_name_dict,\n",
        "                                                  event_name)\n",
        "print(df.head(20))\n",
        "print(test_event_name_dict)"
      ],
      "metadata": {
        "id": "_uD9dRWjm0Xo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd026a5-ac6b-42b3-b8fd-df34d1a175cd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Unnamed: 0  case:concept:name                   time:timestamp  \\\n",
            "0            0                  1 2016-01-01 09:51:15.304000+00:00   \n",
            "1            0                  1 2016-01-01 09:51:15.304000+00:00   \n",
            "2            1                  1 2016-01-01 09:51:15.352000+00:00   \n",
            "3            2                  1 2016-01-01 09:51:15.774000+00:00   \n",
            "4            3                  1 2016-01-01 09:52:36.392000+00:00   \n",
            "5            4                  1 2016-01-01 09:52:36.403000+00:00   \n",
            "6            5                  1 2016-01-01 09:52:36.413000+00:00   \n",
            "7            6                  2 2016-01-01 10:16:11.500000+00:00   \n",
            "8            6                  2 2016-01-01 10:16:11.500000+00:00   \n",
            "9            7                  2 2016-01-01 10:16:11.549000+00:00   \n",
            "10           8                  2 2016-01-01 10:16:11.740000+00:00   \n",
            "11           9                  2 2016-01-01 10:17:31.573000+00:00   \n",
            "12          10                  2 2016-01-01 10:17:31.584000+00:00   \n",
            "13          11                  2 2016-01-01 10:17:31.594000+00:00   \n",
            "14          12                  3 2016-01-01 11:19:38.177000+00:00   \n",
            "15          12                  3 2016-01-01 11:19:38.177000+00:00   \n",
            "16          13                  3 2016-01-01 11:19:38.235000+00:00   \n",
            "17          14                  3 2016-01-01 11:19:38.914000+00:00   \n",
            "18          15                  3 2016-01-01 11:20:37.391000+00:00   \n",
            "19          16                  3 2016-01-01 11:20:37.409000+00:00   \n",
            "\n",
            "    concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  event_idx  \n",
            "0              2   -0.070038     -0.214029       -0.903653          1  \n",
            "1              4   -0.070038     -0.214029       -0.903653          2  \n",
            "2              5   -0.069970     -0.214029       -0.903653          3  \n",
            "3              6   -0.069434     -0.214027       -0.903652          4  \n",
            "4              6    0.045387     -0.213518       -0.903538          5  \n",
            "5              7   -0.070023     -0.214029       -0.903538          6  \n",
            "6              8   -0.070024     -0.214029       -0.903538          7  \n",
            "7              2    1.956020     -0.214029       -0.903653          8  \n",
            "8              4    1.956020     -0.214029       -0.903653          9  \n",
            "9              5   -0.069968     -0.214029       -0.903653         10  \n",
            "10             6   -0.069765     -0.214028       -0.903653         11  \n",
            "11             6    0.044263     -0.213523       -0.903539         12  \n",
            "12             7   -0.070023     -0.214029       -0.903539         13  \n",
            "13             8   -0.070024     -0.214029       -0.903539         14  \n",
            "14             2    5.265518     -0.214029       -0.903653         15  \n",
            "15             4    5.265518     -0.214029       -0.903653         16  \n",
            "16             5   -0.069955     -0.214029       -0.903653         17  \n",
            "17             6   -0.069066     -0.214025       -0.903652         18  \n",
            "18             6    0.013686     -0.213659       -0.903569         19  \n",
            "19             7   -0.070013     -0.214029       -0.903569         20  \n",
            "{'SOC': 2, 'EOC': 3, 'A_Create Application': 4, 'A_Submitted': 5, 'W_Handle leads': 6, 'W_Complete application': 7, 'A_Concept': 8, 'A_Accepted': 9, 'O_Create Offer': 10, 'O_Created': 11, 'O_Sent (mail and online)': 12, 'W_Call after offers': 13, 'A_Complete': 14, 'O_Cancelled': 15, 'W_Validate application': 16, 'A_Validating': 17, 'O_Returned': 18, 'O_Sent (online only)': 19, 'W_Call incomplete files': 20, 'A_Incomplete': 21, 'A_Cancelled': 22, 'O_Accepted': 23, 'A_Pending': 24, 'A_Denied': 25, 'O_Refused': 26, 'W_Assess potential fraud': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, split_idx = get_train_test_split_point(df, test_ratio,\n",
        "                                                case_id=case_id, timestamp=timestamp)\n",
        "print(split_idx)\n",
        "# print the table near the splitting point\n",
        "print(df[split_idx-20:split_idx]) # 20 rows above the splitting point\n",
        "print(df[split_idx:split_idx+20]) # 20 rows below the splitting point"
      ],
      "metadata": {
        "id": "bIuu0pnAwKqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac77d35e-89ad-4b35-987f-8ac2344ad8d4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136903\n",
            "        Unnamed: 0  case:concept:name                   time:timestamp  \\\n",
            "136883      136270               3996 2016-02-24 16:32:43.087000+00:00   \n",
            "136884      136271               3996 2016-02-24 16:32:53.130000+00:00   \n",
            "136885      136272               3996 2016-02-24 16:32:53.146000+00:00   \n",
            "136886      136273               3996 2016-02-24 16:32:53.153000+00:00   \n",
            "136887      136274               3996 2016-02-24 16:32:53.156000+00:00   \n",
            "136888      136275               3996 2016-02-24 16:32:53.158000+00:00   \n",
            "136889      136276               3997 2016-02-24 16:34:50.220000+00:00   \n",
            "136890      136276               3997 2016-02-24 16:34:50.220000+00:00   \n",
            "136891      136277               3997 2016-02-24 16:34:50.229000+00:00   \n",
            "136892      136278               3997 2016-02-24 16:34:50.234000+00:00   \n",
            "136893      136279               3997 2016-02-24 16:34:50.237000+00:00   \n",
            "136894      136280               3996 2016-02-24 16:36:14.290000+00:00   \n",
            "136895      136281               3997 2016-02-24 16:38:17.287000+00:00   \n",
            "136896      136282               3997 2016-02-24 16:39:42.404000+00:00   \n",
            "136897      136283               3997 2016-02-24 16:39:43.778000+00:00   \n",
            "136898      136284               3997 2016-02-24 16:39:55.757000+00:00   \n",
            "136899      136285               3997 2016-02-24 16:39:55.773000+00:00   \n",
            "136900      136286               3997 2016-02-24 16:39:55.781000+00:00   \n",
            "136901      136287               3997 2016-02-24 16:39:55.784000+00:00   \n",
            "136902      136288               3997 2016-02-24 16:39:55.786000+00:00   \n",
            "\n",
            "        concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  event_idx  \n",
            "136883            11   -0.068058     -0.214021       -0.903330     136884  \n",
            "136884            12   -0.055659     -0.213966       -0.903316     136885  \n",
            "136885             7   -0.070016     -0.214029       -0.903316     136886  \n",
            "136886            13   -0.070028     -0.214029       -0.903316     136887  \n",
            "136887            13   -0.070034     -0.214029       -0.903316     136888  \n",
            "136888            14   -0.070036     -0.214029       -0.903316     136889  \n",
            "136889             2    0.097566     -0.214029       -0.903653     136890  \n",
            "136890             4    0.097566     -0.214029       -0.903653     136891  \n",
            "136891             7   -0.070026     -0.214029       -0.903653     136892  \n",
            "136892             7   -0.070031     -0.214029       -0.903653     136893  \n",
            "136893             8   -0.070034     -0.214029       -0.903653     136894  \n",
            "136894            13    0.050305     -0.212754       -0.903031     136895  \n",
            "136895             9    0.106063     -0.212717       -0.903360     136896  \n",
            "136896            10    0.051828     -0.213490       -0.903239     136897  \n",
            "136897            11   -0.068071     -0.214021       -0.903237     136898  \n",
            "136898            12   -0.052887     -0.213953       -0.903220     136899  \n",
            "136899             7   -0.070016     -0.214029       -0.903220     136900  \n",
            "136900            13   -0.070027     -0.214029       -0.903220     136901  \n",
            "136901            13   -0.070034     -0.214029       -0.903220     136902  \n",
            "136902            14   -0.070036     -0.214029       -0.903220     136903  \n",
            "        Unnamed: 0  case:concept:name                   time:timestamp  \\\n",
            "136903      136289               3998 2016-02-24 16:44:54.829000+00:00   \n",
            "136904      136289               3998 2016-02-24 16:44:54.829000+00:00   \n",
            "136905      136290               3998 2016-02-24 16:44:54.879000+00:00   \n",
            "136906      136291               3998 2016-02-24 16:44:55.069000+00:00   \n",
            "136907      136292               3997 2016-02-24 16:45:25.043000+00:00   \n",
            "136908      136293               3998 2016-02-24 16:45:31.598000+00:00   \n",
            "136909      136294               3998 2016-02-24 16:45:31.607000+00:00   \n",
            "136910      136295               3998 2016-02-24 16:45:31.611000+00:00   \n",
            "136911      136296               3911 2016-02-24 16:52:40.206000+00:00   \n",
            "136912      136297               3938 2016-02-24 16:53:20.297000+00:00   \n",
            "136913      136298               3938 2016-02-24 16:53:25.192000+00:00   \n",
            "136914      136299               3938 2016-02-24 16:53:32.049000+00:00   \n",
            "136915      136300               3999 2016-02-24 16:53:32.687000+00:00   \n",
            "136916      136300               3999 2016-02-24 16:53:32.687000+00:00   \n",
            "136917      136301               3999 2016-02-24 16:53:32.738000+00:00   \n",
            "136918      136302               3999 2016-02-24 16:53:33.074000+00:00   \n",
            "136919      136303               3938 2016-02-24 16:53:43.706000+00:00   \n",
            "136920      136304               3793 2016-02-24 16:53:52.290000+00:00   \n",
            "136921      136305               3911 2016-02-24 16:54:08.799000+00:00   \n",
            "136922      136306               3999 2016-02-24 16:54:33.834000+00:00   \n",
            "\n",
            "        concept:name  log_ts_pre  trace_ts_pre  trace_ts_start  event_idx  \n",
            "136903             2    0.358118     -0.214029       -0.903653     136904  \n",
            "136904             4    0.358118     -0.214029       -0.903653     136905  \n",
            "136905             5   -0.069967     -0.214029       -0.903653     136906  \n",
            "136906             6   -0.069766     -0.214028       -0.903653     136907  \n",
            "136907            13   -0.027123     -0.211942       -0.902754     136908  \n",
            "136908             6   -0.060653     -0.213798       -0.903601     136909  \n",
            "136909             7   -0.070026     -0.214029       -0.903601     136910  \n",
            "136910             8   -0.070033     -0.214029       -0.903601     136911  \n",
            "136911             7    0.543605     -0.206310       -0.773688     136912  \n",
            "136912             7   -0.012638     -0.079384       -0.798332     136913  \n",
            "136913             7   -0.063030     -0.213998       -0.798325     136914  \n",
            "136914             7   -0.060221     -0.213986       -0.798316     136915  \n",
            "136915             2   -0.069125     -0.214029       -0.903653     136916  \n",
            "136916             4   -0.069125     -0.214029       -0.903653     136917  \n",
            "136917             5   -0.069965     -0.214029       -0.903653     136918  \n",
            "136918             6   -0.069557     -0.214027       -0.903652     136919  \n",
            "136919             7   -0.054816     -0.213955       -0.798299     136920  \n",
            "136920             7   -0.057748     -0.200024       -0.636448     136921  \n",
            "136921             7   -0.046402     -0.213468       -0.773563     136922  \n",
            "136922             6   -0.034194     -0.213644       -0.903566     136923  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of test_log_prefix_tensor\n",
        "\n",
        "87324 - Number of events in test set used for creating log prefix (i.e. number of events excluding EOC)\n",
        "\n",
        "30 - Length of log prefix\n",
        "\n",
        "29 - dimension of one-hot encoding (i.e. num_act, which is 28) + number of time features (which is 1 for log prefix)"
      ],
      "metadata": {
        "id": "AjcQ_BO6opYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Create test_log_prefix_tensor, test_trace_prefix_tensor, test_suffix_act_tensor, test_suffix_time_tensor\n",
        "test_log_prefix_tensor = create_log_prefix_tensor(df, log_prefix_length, set_name, test_ratio, num_act,\n",
        "                                                    log_col_name, categorical_features, case_id, timestamp, event_name)\n",
        "print(test_log_prefix_tensor.shape)\n",
        "print(test_log_prefix_tensor[:5])"
      ],
      "metadata": {
        "id": "I4648K6Lm5eO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e57ecd1-9dfc-4296-eb35-d7c9b7664bde"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([87324, 30, 29])\n",
            "tensor([[[ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.04],\n",
            "         ...,\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         [ 0.00,  0.00,  1.00,  ...,  0.00,  0.00,  0.36]],\n",
            "\n",
            "        [[ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.04],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00,  0.07],\n",
            "         ...,\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         [ 0.00,  0.00,  1.00,  ...,  0.00,  0.00,  0.36],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00,  0.36]],\n",
            "\n",
            "        [[ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.04],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00,  0.07],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         ...,\n",
            "         [ 0.00,  0.00,  1.00,  ...,  0.00,  0.00,  0.36],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00,  0.36],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07]],\n",
            "\n",
            "        [[ 0.00,  0.00,  0.00,  ...,  0.00,  0.00,  0.07],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.04],\n",
            "         ...,\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00,  0.36],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07]],\n",
            "\n",
            "        [[ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.04],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.05],\n",
            "         ...,\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.07],\n",
            "         [ 0.00,  0.00,  0.00,  ...,  0.00,  0.00, -0.03]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of test_trace_prefix_tensor\n",
        "\n",
        "87324 - Number of events in test set used for creating trace prefix (i.e. number of events excluding EOC)\n",
        "\n",
        "15 - Length of trace prefix\n",
        "\n",
        "30 - dimension of one-hot encoding (i.e. num_act, which is 28) + number of time features (which is 2 for trace prefix)"
      ],
      "metadata": {
        "id": "34hk3mwlqvDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_trace_prefix_tensor = create_trace_prefix_tensor(df, trace_prefix_length, set_name, test_ratio, num_act,\n",
        "                                                      trace_prefix_col_name, categorical_features, event_idx, case_id, timestamp, event_name)\n",
        "print(test_trace_prefix_tensor.shape)\n",
        "print(test_trace_prefix_tensor[:5])"
      ],
      "metadata": {
        "id": "gdQ6ku_Tm9uI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6fce46d-a67f-4e10-f8ca-90ac8daa7af3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([87324, 15, 30])\n",
            "tensor([[[     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      1.00,  ...,      0.00,     -0.90,\n",
            "              -0.21]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      1.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      1.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21]],\n",
            "\n",
            "        [[     0.00,      0.00,      0.00,  ...,      0.00, -10000.00,\n",
            "          -10000.00],\n",
            "         [     0.00,      0.00,      1.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         ...,\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21],\n",
            "         [     0.00,      0.00,      0.00,  ...,      0.00,     -0.90,\n",
            "              -0.21]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of test_suffix_act_tensor\n",
        "\n",
        "87324 - Number of events in test set used for creating suffix (i.e. number of events excluding EOC)\n",
        "\n",
        "35 - Length of suffix"
      ],
      "metadata": {
        "id": "1cRmJr02rHZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_suffix_act_tensor, test_suffix_time_tensor = create_trace_suffix_tensor(df, trace_suffix_length, set_name, test_ratio,\n",
        "                                                                                trace_suffix_col_name, categorical_features, event_idx, case_id, timestamp, event_name)\n",
        "print(test_suffix_act_tensor.shape)\n",
        "print(test_suffix_act_tensor[:5])"
      ],
      "metadata": {
        "id": "h3YwtFounUn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d91dc19f-d7b6-434f-ff7b-0ecaf4503b12"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([87324, 35])\n",
            "tensor([[ 4,  5,  6,  6,  7,  8,  7,  9, 10, 11, 12,  7, 13, 13, 14, 13, 13, 13,\n",
            "         13, 16, 16, 17, 18, 16, 16, 20, 20, 21, 20, 20, 20, 20, 16, 16, 17],\n",
            "        [ 5,  6,  6,  7,  8,  7,  9, 10, 11, 12,  7, 13, 13, 14, 13, 13, 13, 13,\n",
            "         16, 16, 17, 18, 16, 16, 20, 20, 21, 20, 20, 20, 20, 16, 16, 17, 16],\n",
            "        [ 6,  6,  7,  8,  7,  9, 10, 11, 12,  7, 13, 13, 14, 13, 13, 13, 13, 16,\n",
            "         16, 17, 18, 16, 16, 20, 20, 21, 20, 20, 20, 20, 16, 16, 17, 16, 23],\n",
            "        [ 6,  7,  8,  7,  9, 10, 11, 12,  7, 13, 13, 14, 13, 13, 13, 13, 16, 16,\n",
            "         17, 18, 16, 16, 20, 20, 21, 20, 20, 20, 20, 16, 16, 17, 16, 23, 24],\n",
            "        [13, 13, 22, 15, 13,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_suffix_time_tensor.shape)\n",
        "print(test_suffix_time_tensor[:5])"
      ],
      "metadata": {
        "id": "0H1BpIZtUhLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168be783-c37f-4c64-db7c-72b250f917d3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([87324, 35])\n",
            "tensor([[    -0.21,     -0.21,     -0.21,     -0.21,     -0.21,     -0.21,\n",
            "             -0.19,     -0.21,     -0.21,     -0.21,     -0.21,     -0.21,\n",
            "             -0.21,     -0.21,     -0.21,     -0.21,      2.37,     -0.21,\n",
            "              8.52,     -0.21,     -0.21,     -0.21,     -0.21,     -0.21,\n",
            "             -0.10,     -0.21,     -0.21,     -0.21,     -0.21,     -0.17,\n",
            "             -0.21,      0.14,     -0.21,     -0.21,     -0.21],\n",
            "        [    -0.21,     -0.21,     -0.21,     -0.21,     -0.21,     -0.19,\n",
            "             -0.21,     -0.21,     -0.21,     -0.21,     -0.21,     -0.21,\n",
            "             -0.21,     -0.21,     -0.21,      2.37,     -0.21,      8.52,\n",
            "             -0.21,     -0.21,     -0.21,     -0.21,     -0.21,     -0.10,\n",
            "             -0.21,     -0.21,     -0.21,     -0.21,     -0.17,     -0.21,\n",
            "              0.14,     -0.21,     -0.21,     -0.21,     -0.21],\n",
            "        [    -0.21,     -0.21,     -0.21,     -0.21,     -0.19,     -0.21,\n",
            "             -0.21,     -0.21,     -0.21,     -0.21,     -0.21,     -0.21,\n",
            "             -0.21,     -0.21,      2.37,     -0.21,      8.52,     -0.21,\n",
            "             -0.21,     -0.21,     -0.21,     -0.21,     -0.10,     -0.21,\n",
            "             -0.21,     -0.21,     -0.21,     -0.17,     -0.21,      0.14,\n",
            "             -0.21,     -0.21,     -0.21,     -0.21,     -0.10],\n",
            "        [    -0.21,     -0.21,     -0.21,     -0.19,     -0.21,     -0.21,\n",
            "             -0.21,     -0.21,     -0.21,     -0.21,     -0.21,     -0.21,\n",
            "             -0.21,      2.37,     -0.21,      8.52,     -0.21,     -0.21,\n",
            "             -0.21,     -0.21,     -0.21,     -0.10,     -0.21,     -0.21,\n",
            "             -0.21,     -0.21,     -0.17,     -0.21,      0.14,     -0.21,\n",
            "             -0.21,     -0.21,     -0.21,     -0.10,     -0.21],\n",
            "        [     2.39,     -0.21,     13.95,     -0.21,     -0.21,     -0.21,\n",
            "         -10000.00, -10000.00, -10000.00, -10000.00, -10000.00, -10000.00,\n",
            "         -10000.00, -10000.00, -10000.00, -10000.00, -10000.00, -10000.00,\n",
            "         -10000.00, -10000.00, -10000.00, -10000.00, -10000.00, -10000.00,\n",
            "         -10000.00, -10000.00, -10000.00, -10000.00, -10000.00, -10000.00,\n",
            "         -10000.00, -10000.00, -10000.00, -10000.00, -10000.00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Build TensorDataset\n",
        "test_dataset = TensorDataset(test_log_prefix_tensor, test_trace_prefix_tensor, test_suffix_act_tensor, test_suffix_time_tensor)\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "id": "PyHeH8hmncw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0587832e-7954-4815-db45-faa74d2c8f79"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Build test_dataloader, valid_dataloader\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "16ukNKpInmli"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run experiment"
      ],
      "metadata": {
        "id": "Mn1UXQKTB-8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_act = 28\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "num_layers = 2\n",
        "\n",
        "enc_hidden_size = 50\n",
        "log_enc_input_size = num_act + 1\n",
        "trace_enc_input_size = num_act + 2\n",
        "\n",
        "dec_hidden_size = 50 # For seq2seq_one_input, seq2seq_add, seq2seq_mul\n",
        "dec_cat_hidden_size = 100 # For seq2seq_cat\n",
        "\n",
        "act_dec_input_size = num_act\n",
        "act_dec_output_size = num_act\n",
        "\n",
        "time_dec_input_size = 1\n",
        "time_dec_output_size = 1"
      ],
      "metadata": {
        "id": "jNByknYFCBBR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define encoder and decoder\n",
        "log_encoder = Encoder(input_size=log_enc_input_size,\n",
        "                      hidden_size=enc_hidden_size,\n",
        "                      num_layers=num_layers).to(device)\n",
        "\n",
        "trace_encoder = Encoder(input_size=trace_enc_input_size,\n",
        "                        hidden_size=enc_hidden_size,\n",
        "                        num_layers=num_layers).to(device)\n",
        "\n",
        "act_decoder = Decoder(input_size=act_dec_input_size,\n",
        "                      hidden_size=dec_hidden_size,\n",
        "                      output_size=act_dec_output_size,\n",
        "                      num_layers=num_layers).to(device)\n",
        "\n",
        "time_decoder = Decoder(input_size=time_dec_input_size,\n",
        "                      hidden_size=dec_hidden_size,\n",
        "                      output_size=time_dec_output_size,\n",
        "                      num_layers=num_layers).to(device)\n",
        "\n",
        "act_cat_decoder = Decoder(input_size=act_dec_input_size,\n",
        "                      hidden_size=dec_cat_hidden_size,\n",
        "                      output_size=act_dec_output_size,\n",
        "                      num_layers=num_layers).to(device)\n",
        "\n",
        "time_cat_decoder = Decoder(input_size=time_dec_input_size,\n",
        "                      hidden_size=dec_cat_hidden_size,\n",
        "                      output_size=time_dec_output_size,\n",
        "                      num_layers=num_layers).to(device)"
      ],
      "metadata": {
        "id": "mZbwPdnzDGrB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop\n",
        "def training(model, dataloader, teacher_forcing_ratio=0.5):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Define loss function\n",
        "    act_criterion = nn.CrossEntropyLoss(ignore_index=0) # target value 0 is ignored and does not contribute to the input gradient\n",
        "    time_criterion = nn.L1Loss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for batch in dataloader:\n",
        "\n",
        "            train_log_prefix, train_trace_prefix, train_suffix_act, train_suffix_time = batch\n",
        "            train_log_prefix = train_log_prefix.float().to(device)\n",
        "            # train_log_prefix shape: (batch_size, log_prefix_len, num_act + 1)\n",
        "            train_trace_prefix = train_trace_prefix.float().to(device)\n",
        "            # train_trace_prefix shape: (batch_size, trace_prefix_len, num_act + 2)\n",
        "            train_suffix_act = train_suffix_act.to(torch.long).to(device)\n",
        "            # train_suffix_act shape: (batch_size, suffix_len)\n",
        "            train_suffix_time = train_suffix_time.float().to(device)\n",
        "            # train_suffi_time shape: (batch_size, suffix_len)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if model == model_log:\n",
        "                act_predictions, time_predictions = model(train_log_prefix, train_suffix_act, train_suffix_time, teacher_forcing_ratio)\n",
        "\n",
        "            elif model == model_trace:\n",
        "                act_predictions, time_predictions = model(train_trace_prefix, train_suffix_act, train_suffix_time, teacher_forcing_ratio)\n",
        "\n",
        "            else:\n",
        "                act_predictions, time_predictions = model(train_log_prefix, train_trace_prefix, train_suffix_act, train_suffix_time, teacher_forcing_ratio)\n",
        "\n",
        "            act_predictions = act_predictions.to(device)\n",
        "            # act_predictions shape: (batch_size, suffix_len, num_act)\n",
        "            time_predictions = time_predictions.to(device)\n",
        "            # time_predictions shape: (batch_size, suffix_len, 1)\n",
        "\n",
        "            # Mask padding (-10000) in the timestamp suffix so that they do not contribute to the input gradient\n",
        "            train_suffix_time = train_suffix_time.unsqueeze(-1) # To match the dimension of time_predictions\n",
        "            # train_suffix_time shape: (batch_size, suffix_len, 1)\n",
        "            mask = (train_suffix_time != -10000).to(device)\n",
        "            masked_train_suffix_time = torch.masked_select(train_suffix_time, mask) # The result is a 1D tensor\n",
        "            masked_time_predictions = torch.masked_select(time_predictions, mask) # The result is a 1D tensor\n",
        "\n",
        "            # nn.CrossEntropyLoss requires input shape (batch_size, num_act), target shape (batch_size)\n",
        "            act_predictions = act_predictions.view(-1, act_predictions.size(-1))\n",
        "            # act_predictions shape: (batch_size * seq_length, num_act)\n",
        "            train_suffix_act = train_suffix_act.view(-1)\n",
        "            # train_suffix_act shape: (batch_size * seq_length)\n",
        "\n",
        "            act_loss = act_criterion(act_predictions, train_suffix_act)\n",
        "            time_loss = time_criterion(masked_time_predictions, masked_train_suffix_time)\n",
        "\n",
        "            loss = 0.5 * act_loss + 0.5 * time_loss\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / len(dataloader)\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "          print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "ESNfV6erUoA4"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, dataloader, teacher_forcing_ratio=0):\n",
        "\n",
        "    model.eval()\n",
        "    epoch_act_loss = 0\n",
        "    epoch_time_loss = 0\n",
        "\n",
        "    time_criterion = nn.L1Loss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in dataloader:\n",
        "\n",
        "            test_log_prefix, test_trace_prefix, test_suffix_act, test_suffix_time = batch\n",
        "            test_log_prefix = test_log_prefix.float().to(device)\n",
        "            # test_log_prefix shape: (batch_size, log_prefix_len, num_act + 1)\n",
        "            test_trace_prefix = test_trace_prefix.float().to(device)\n",
        "            # test_trace_prefix shape: (batch_size, trace_prefix_len, num_act + 2)\n",
        "            test_suffix_act = test_suffix_act.to(torch.long).to(device)\n",
        "            # test_suffix_act: (batch_size, suffix_len)\n",
        "            test_suffix_time = test_suffix_time.float().to(device)\n",
        "            # test_suffi_time: (batch_size, suffix_len)\n",
        "\n",
        "            if model == model_log:\n",
        "                act_predictions, time_predictions = model(test_log_prefix, test_suffix_act, test_suffix_time, teacher_forcing_ratio)\n",
        "\n",
        "            elif model == model_trace:\n",
        "                act_predictions, time_predictions = model(test_trace_prefix, test_suffix_act, test_suffix_time, teacher_forcing_ratio)\n",
        "\n",
        "            else:\n",
        "                act_predictions, time_predictions = model(test_log_prefix, test_trace_prefix, test_suffix_act, test_suffix_time, teacher_forcing_ratio)\n",
        "\n",
        "            act_predictions = act_predictions.to(device)\n",
        "            # act_predictions shape: (batch_size, suffix_len, num_act)\n",
        "            time_predictions = time_predictions.to(device)\n",
        "            # time_predictions shape: (batch_size, suffix_len, 1)\n",
        "\n",
        "            # Mask padding (-10000) in the timestamp suffix so that they do not contribute to the loss\n",
        "            test_suffix_time = test_suffix_time.unsqueeze(-1)\n",
        "            # train_suffix_time shape: batch_size, suffix_len, 1\n",
        "            mask = (test_suffix_time != -10000).to(device)\n",
        "            masked_test_suffix_time = torch.masked_select(test_suffix_time, mask) # The result is a 1D tensor\n",
        "            masked_time_predictions = torch.masked_select(time_predictions, mask) # The result is a 1D tensor\n",
        "\n",
        "            act_loss = normalized_DL_distance(act_predictions, test_suffix_act)\n",
        "            time_loss = time_criterion(masked_time_predictions, masked_test_suffix_time)\n",
        "\n",
        "            epoch_act_loss += act_loss\n",
        "            epoch_time_loss += time_loss.item()\n",
        "\n",
        "        avg_act_loss = epoch_act_loss / len(dataloader)\n",
        "        avg_time_loss = epoch_time_loss / len(dataloader)\n",
        "\n",
        "        return avg_act_loss, avg_time_loss"
      ],
      "metadata": {
        "id": "bliRl3dy6vfm"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_log = Seq2Seq_one_input(num_act=num_act,\n",
        "                              encoder=log_encoder,\n",
        "                              act_decoder=act_decoder,\n",
        "                              time_decoder=time_decoder).to(device)"
      ],
      "metadata": {
        "id": "mLGIr6Qb8BnE"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training(model_log, train_dataloader)"
      ],
      "metadata": {
        "id": "oJ_WX3j6Uq8F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9e9621-fec0-44e7-cc5a-57335cfd7115"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Average Loss: 0.4898\n",
            "Epoch 10/10, Average Loss: 0.4718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_log.state_dict(), 'model_log_checkpoint.pth')"
      ],
      "metadata": {
        "id": "BOysat-FC0rf"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_log.load_state_dict(torch.load('model_log_checkpoint.pth'))"
      ],
      "metadata": {
        "id": "WDIQjQ6GC3L4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5504bdab-29f3-4d37-d9b0-1c8c76c4560d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-60f3191466cf>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_log.load_state_dict(torch.load('model_log_checkpoint.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "act_loss, time_loss = evaluation(model_log, test_dataloader)\n",
        "print(\"DL distance for activity label suffix prediction:\", act_loss)\n",
        "print(\"MAE for timestamp suffix prediction:\", time_loss)"
      ],
      "metadata": {
        "id": "UgZlfgE78JY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d4d2b8-56d3-476d-ce98-f6921c91c1d6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DL distance for activity label suffix prediction: 0.6711827658578029\n",
            "MAE for timestamp suffix prediction: 0.31808089867179645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_trace = Seq2Seq_one_input(num_act=num_act,\n",
        "                                encoder=trace_encoder,\n",
        "                                act_decoder=act_decoder,\n",
        "                                time_decoder=time_decoder).to(device)"
      ],
      "metadata": {
        "id": "BgPSflf68C_l"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training(model_trace, train_dataloader)"
      ],
      "metadata": {
        "id": "QJN01cKLkguR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5994ce0-62b0-4fd7-9d9b-20d65df5ed18"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Average Loss: 0.4367\n",
            "Epoch 10/10, Average Loss: 0.4317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_trace.state_dict(), 'model_trace_checkpoint.pth')"
      ],
      "metadata": {
        "id": "R9G2T1e-C5z5"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_trace.load_state_dict(torch.load('model_trace_checkpoint.pth'))"
      ],
      "metadata": {
        "id": "WRT12V8hDS0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4cc69a0-a0d4-4c35-cf02-8038f9521392"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-f3af29437025>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_trace.load_state_dict(torch.load('model_trace_checkpoint.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "act_loss, time_loss = evaluation(model_trace, test_dataloader)\n",
        "print(\"DL distance for activity label suffix prediction:\", act_loss)\n",
        "print(\"MAE for timestamp suffix prediction:\", time_loss)"
      ],
      "metadata": {
        "id": "rfxjuZAH8SwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5da236e-64d8-4052-9a75-2a63b3deebdd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DL distance for activity label suffix prediction: 0.6502332185086889\n",
            "MAE for timestamp suffix prediction: 0.2663606502852597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_cat = Seq2Seq_cat(num_act=num_act,\n",
        "                        log_encoder=log_encoder,\n",
        "                        trace_encoder=trace_encoder,\n",
        "                        act_cat_decoder=act_cat_decoder,\n",
        "                        time_cat_decoder=time_cat_decoder).to(device)"
      ],
      "metadata": {
        "id": "SI7uJbLC8Esw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training(model_cat, train_dataloader)"
      ],
      "metadata": {
        "id": "kcUajhsnkmTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bad0185-3b2a-467a-ef22-555b3c4e3cb8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Average Loss: 0.4616\n",
            "Epoch 10/10, Average Loss: 0.4481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_cat.state_dict(), 'model_cat_checkpoint.pth')"
      ],
      "metadata": {
        "id": "GHeKgMzNDcnQ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cat.load_state_dict(torch.load('model_cat_checkpoint.pth'))"
      ],
      "metadata": {
        "id": "-2n7geHHDfRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "410e4efa-669f-4221-9a59-0eaf306c8e76"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-71-64ff29b293cb>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_cat.load_state_dict(torch.load('model_cat_checkpoint.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "act_loss, time_loss = evaluation(model_cat, test_dataloader)\n",
        "print(\"DL distance for activity label suffix prediction:\", act_loss)\n",
        "print(\"MAE for timestamp suffix prediction:\", time_loss)"
      ],
      "metadata": {
        "id": "Usc7UQcA8WIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc4c144-e14c-41dd-8790-36b425c3ceee"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DL distance for activity label suffix prediction: 0.6329113824984581\n",
            "MAE for timestamp suffix prediction: 0.28600139231472227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_add = Seq2Seq_add(num_act=num_act,\n",
        "                        log_encoder=log_encoder,\n",
        "                        trace_encoder=trace_encoder,\n",
        "                        act_decoder=act_decoder,\n",
        "                        time_decoder=time_decoder).to(device)"
      ],
      "metadata": {
        "id": "796rxuvv8GUW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training(model_add, train_dataloader)"
      ],
      "metadata": {
        "id": "Yf28sBg2k1Mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d1384b-5992-4a04-c98b-e88c73828581"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Average Loss: 0.4278\n",
            "Epoch 10/10, Average Loss: 0.5166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_add.state_dict(), 'model_add_checkpoint.pth')"
      ],
      "metadata": {
        "id": "pj7acE4JbYrX"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_add.load_state_dict(torch.load('model_add_checkpoint.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2U1npnGbZBP",
        "outputId": "8af21147-9c75-447e-a990-10c78ffe9693"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-76-92ed8b8c731f>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_add.load_state_dict(torch.load('model_add_checkpoint.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "act_loss, time_loss = evaluation(model_add, test_dataloader)\n",
        "print(\"DL distance for activity label suffix prediction:\", act_loss)\n",
        "print(\"MAE for timestamp suffix prediction:\", time_loss)"
      ],
      "metadata": {
        "id": "oJoNdgKt8Rjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6719782f-70d2-40a3-bec8-4b6d63d84b53"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DL distance for activity label suffix prediction: 0.6319158765888663\n",
            "MAE for timestamp suffix prediction: 0.3025603502006321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_mul = Seq2Seq_mul(num_act=num_act,\n",
        "                        log_encoder=log_encoder,\n",
        "                        trace_encoder=trace_encoder,\n",
        "                        act_decoder=act_decoder,\n",
        "                        time_decoder=time_decoder).to(device)"
      ],
      "metadata": {
        "id": "0AT2o6Tf8H1U"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training(model_mul, train_dataloader)"
      ],
      "metadata": {
        "id": "V8AbFb2bk3eC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e0655f3-187a-4ad6-8003-66364eac9df3"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Average Loss: 0.4714\n",
            "Epoch 10/10, Average Loss: 0.4440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_mul.state_dict(), 'model_mul_checkpoint.pth')"
      ],
      "metadata": {
        "id": "LmYwRh5HESSZ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mul.load_state_dict(torch.load('model_mul_checkpoint.pth'))"
      ],
      "metadata": {
        "id": "Dnc3O_qYESlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6563543d-b277-412c-c275-fc320e3dc5ac"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-bce2518012ae>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_mul.load_state_dict(torch.load('model_mul_checkpoint.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "act_loss, time_loss = evaluation(model_mul, test_dataloader)\n",
        "print(\"DL distance for activity label suffix prediction:\", act_loss)\n",
        "print(\"MAE for timestamp suffix prediction:\", time_loss)"
      ],
      "metadata": {
        "id": "GkVXl4F48Z4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc715b6-1864-4ecf-8ebc-4fa1c3c67b24"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DL distance for activity label suffix prediction: 0.5929331144964682\n",
            "MAE for timestamp suffix prediction: 0.28569949521468235\n"
          ]
        }
      ]
    }
  ]
}